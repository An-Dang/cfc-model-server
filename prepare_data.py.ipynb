{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting datat from xnli and rte3, cleaning and combining them in on big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import xml\n",
    "\n",
    "data_path = \"data/\"\n",
    "rte3_path = data_path + \"rte3/\"\n",
    "xnli_path = data_path + \"xnli/\"\n",
    "\n",
    "preprocessed_path = data_path + \"preprocessed/\"\n",
    "rte3_preprocessed_path = os.path.join(preprocessed_path, \"rte3.tsv\")\n",
    "xnli_preprocessed_path = os.path.join(preprocessed_path, \"xnli.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process RTE3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                           sentenceA  \\\n",
       " 0  Hallo Folgendes Problem, der CPU ist bei 100%....   \n",
       " 1  Hallo, habe mir ein Asus P5Q geholt und am Anf...   \n",
       " 2  hallo liebe mods, ich schreibe diesen beitrag ...   \n",
       " 3  Hallo, ich habe Probleme mit dem Trojaner '' T...   \n",
       " 4  Hallo, ich habe Probleme mit dem Trojaner '' T...   \n",
       " \n",
       "                                            sentenceB       label  \n",
       " 0  Der Computer ist durch Malware verseucht, der ...  entailment  \n",
       " 1  Die USB-Anschl√ºsse funktionieren bei dem neuen...  entailment  \n",
       " 2  Beim Aufrufen des p5q deluxe Sammelthreads bek...  entailment  \n",
       " 3            Ein Trojaner kann nicht entfernt werden  entailment  \n",
       " 4  Mein Virenprogramm AntiVir meldet immer wieder...  entailment  ,\n",
       " 3014)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=[\"sentenceA\", \"sentenceB\", \"label\"]\n",
    "dataframe = pd.DataFrame(columns=columns)\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "devel_file = os.path.join(rte3_path, \"german_social_media_DEVEL.xml\")\n",
    "test_file = os.path.join(rte3_path, \"german_social_media_TEST.xml\")\n",
    "\n",
    "\n",
    "def parse_and_collect(filepath, rte3_dataframe):\n",
    "    dom = ET.parse(filepath)\n",
    "    for pair in dom.iter(\"pair\"):\n",
    "        if pair.tag == \"pair\":\n",
    "            label = pair.attrib[\"entailment\"]\n",
    "            sentenceA = pair[0].text\n",
    "            sentenceB = pair[1].text\n",
    "\n",
    "            rte3_dataframe = rte3_dataframe.append({\"sentenceA\": sentenceA, \"sentenceB\": sentenceB, \"label\": label.lower().replace(\"nonentailment\",\"contradiction\")}, ignore_index=True)\n",
    "    return rte3_dataframe\n",
    "\n",
    "dataframe = parse_and_collect(devel_file, dataframe)\n",
    "dataframe = parse_and_collect(test_file, dataframe)\n",
    "dataframe.to_csv(os.path.join(data_path + \"preprocessed\", \"rte3.tsv\"),sep=\"\\t\", encoding=\"utf8\", index=False)\n",
    "\n",
    "dataframe.head(), len(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process XNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                           sentenceA  \\\n",
       " 0            und er hat gesagt, Mama ich bin daheim.   \n",
       " 1            und er hat gesagt, Mama ich bin daheim.   \n",
       " 2            und er hat gesagt, Mama ich bin daheim.   \n",
       " 3  Ich wusste nicht was ich vorhatte oder so, ich...   \n",
       " 4  Ich wusste nicht was ich vorhatte oder so, ich...   \n",
       " \n",
       "                                            sentenceB          label  \n",
       " 0  Er rief seine Mutter an, sobald er aus dem Sch...        neutral  \n",
       " 1                                Er sagte kein Wort.  contradiction  \n",
       " 2  Er sagte seiner Mutter, er sei nach Hause geko...     entailment  \n",
       " 3  Ich war noch nie in Washington, deshalb habe i...        neutral  \n",
       " 4  Ich wusste genau, was ich tun musste, als ich ...  contradiction  ,\n",
       " 7500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=[\"sentenceA\", \"sentenceB\", \"label\"]\n",
    "dataframe = pd.DataFrame(columns=columns)\n",
    "\n",
    "devel_file = os.path.join(xnli_path, \"xnli.dev.tsv\")\n",
    "test_file = os.path.join(xnli_path, \"xnli.test.tsv\")\n",
    "\n",
    "def parse_and_collect(filepath, xnli_dataframe):\n",
    "    xnli_data = pd.read_csv(filepath, encoding=\"utf8\", sep='\\t')\n",
    "    for idx, row in xnli_data.iterrows():\n",
    "        if row[\"language\"] == \"de\":\n",
    "            xnli_dataframe = xnli_dataframe.append({\"sentenceA\": row[\"sentence1\"], \"sentenceB\": row[\"sentence2\"], \"label\": row[\"gold_label\"].lower()}, ignore_index=True)\n",
    "    return xnli_dataframe\n",
    "    \n",
    "dataframe = parse_and_collect(devel_file, dataframe)\n",
    "dataframe = parse_and_collect(test_file, dataframe)\n",
    "dataframe.to_csv(os.path.join(data_path + \"preprocessed\", \"xnli.tsv\"), sep=\"\\t\", encoding=\"utf8\", index=False)\n",
    "\n",
    "dataframe.head(), len(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combin both and build sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnli_dataframe = pd.read_csv(rte3_preprocessed_path, encoding=\"utf8\", sep='\\t')\n",
    "rte3_dataframe = pd.read_csv(xnli_preprocessed_path, encoding=\"utf8\", sep='\\t')\n",
    "\n",
    "all_data = pd.concat([xnli_dataframe, rte3_dataframe])\n",
    "all_data = all_data.sample(frac=1)\n",
    "\n",
    "train_size=0.8\n",
    "train_set = all_data.sample(frac=train_size, random_state=0)\n",
    "test_set = all_data.drop(train_set.index)\n",
    "\n",
    "train_set.to_csv(os.path.join(preprocessed_path, \"train.tsv\"), sep=\"\\t\", encoding=\"utf8\", index=False)\n",
    "test_set.to_csv(os.path.join(preprocessed_path, \"test.tsv\"), sep=\"\\t\", encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
